---
title: "Comparative of Classification Machine Learning Algorithms"
output: github_document
---

```{r}
library(ggplot2)
library(readxl)
library(tidyverse)
library(arsenal)
library(caret)
library(rpart)
library(rpart.plot)
library(randomForest) 
library(gbm)
library(arsenal)
library(pROC)
```


```{r}
#located the data at the specified file path and stores the data in a variable called "data"
data <- read_excel("/Users/jaimerd/Desktop/master/Human Resources Analytics /data.xlsx")
```

```{r}
#summary of the data
summary(data)
```

Feature engineering

```{r}
#convert character (text) variables into factors
data <- data %>% mutate_if(is.character,as.factor)

#convert ordinal and categorical variables into factors
colums_factor <- c("Education", "EnvironmentSatisfaction", "JobInvolvement", "JobLevel", "JobSatisfaction", "PerformanceRating", "RelationshipSatisfaction", "StockOptionLevel", "WorkLifeBalance")
data[colums_factor] <- lapply(data[colums_factor], as.factor)
```

## Incorrect Data

```{r}

#department  
data <- data %>% 
  mutate(Department = recode(Department, 'HR' = 'Human Resources')) %>%
  mutate(Department = recode(Department, 'R & D' = "Research & Development"))
```

## Check for outliers

```{r}
#Age
boxplot(data$Age)
summary(data$Age)
data %>% count(Age>70) 
data %>% count(Age<18)
data$Age[data$Age > 70] <- NA
data$Age[data$Age < 10] <- NA

#Billable Rate
boxplot(data$BillableRate)

#Distance From Home 
boxplot(data$DistanceFromHome)

#Hourly pay rate
boxplot(data$HourlyPayRate)

#Monthly income
boxplot(data$MonthlyIncome)
summary(data$MonthlyIncome)

#Monthly rate
boxplot(data$MonthlyRate)

#Salary hike
boxplot(data$PercentSalaryHike)

#Years with current manager
table(data$YearsWithCurrManager)

#exclude ID, DOB and Over 18 variables because they are not going to have any implications in the model 
data <- data %>%  select(-ID)
data <- data %>%  select(-DOB)
data <-data %>% select(-Over18)

```

## Statistic summary and correlation analysis

ANOVA Test for numerical variables and Chi Squared Test for categotical Variables. Takin <0.01 as the reference value 

```{r}
my_controls <- tableby.control(
  test = T,
  total = FALSE,
  numeric.test = "anova", cat.test = "chisq",
  numeric.stats = c("meansd"),
  cat.stats = c("countpct"),
  )

descriptive_stats <- tableby(Attrition ~ .,
                             data = data,
                             control = my_controls)

summary(descriptive_stats, title = "Descriptive Statistic", text= TRUE)
```


## Model Construction and Comparative

```{r}
#omit missing values
data <- na.omit(data)

set.seed(0000)

#split the data 
index <- createDataPartition(data$Attrition, p = 0.8, list = FALSE)
train <- data[index,]
test <- data[-index, ]
```


## Decision Tree

```{r}
tree <- rpart(Attrition~., data = train, method = "class")
tree
```


Check accuracy with test data

```{r}
predictions <- predict(tree, test, type = "class")
postResample(predictions, test$Attrition)
```

Confusion matrix

```{r}
cm_tree <- confusionMatrix(data = predictions, test$Attrition, positive = "Yes")
cm_tree
```


ROC curve

```{r}
predictions1 <- predict(tree, test, type = "prob")
probabilities <- predictions1[, "Yes"]
roc_curve <- roc(test$Attrition, probabilities)
area1 <- auc(roc_curve)
plot(roc_curve, main = "ROC Curve Decision Tree")
text(x = 0.6, y = 0.2, labels = paste("AUC:", round(area1, 2)))
```


## Random Forrest

```{r}
rf <- randomForest(Attrition ~ ., data = train)
rf
```

check accuracy with the test data

```{r}
pred_rf <- predict(rf,test)
postResample(pred_rf, test$Attrition)
```

Confusion matrix

```{r}
cm_rf <- confusionMatrix(pred_rf,test$Attrition, positive = "Yes")
cm_rf
```

ROC Curve

```{r}
pred_rf_prob <- predict(rf, test, type = "prob")
probabilities_rf <- pred_rf_prob[, "Yes"]
roc_curve_rf <- roc(test$Attrition, probabilities_rf)
auc_rf <- auc(roc_curve_rf)
plot(roc_curve_rf, main = "ROC Curve Random Forest Model")
text(x = 0.6, y = 0.2, labels = paste("AUC:", round(auc_rf, 2)))
```


## Gradient Boosting

```{r}
# Convert "Yes" to 1 and "No" to 0 in the 'Attrition' variable
train$Attrition <- ifelse(train$Attrition == "Yes", 1, 0)
```

```{r}
# Fit the GBM model
gb <- gbm(Attrition ~ .,
                 data = train,
                 distribution = "bernoulli",
                 n.trees = 500,
                 shrinkage = 0.01,
                 interaction.depth = 3,
                 cv.folds = 10,
                 n.minobsinnode = 10)
```


Accuracy with the test data
```{r}
pred_gb <- predict(gb, test, n.trees = gb$n.trees, type = "response")
```

From probabilities to labels 

```{r}
pred_labels <- ifelse(pred_gb > 0.5, "Yes", "No")
```

Confusion Matrix

```{r}
cm_gb <- confusionMatrix(as.factor(pred_labels), test$Attrition, positive = "Yes")
print(cm_gb)
```


ROC Curve

```{r}
roc_curve_gb <- roc(test$Attrition, pred_gb)
auc_gb <- auc(roc_curve_gb)
plot(roc_curve_gb, main = "ROC Curve for GBM Model")
text(x = 0.6, y = 0.2, labels = paste("AUC:", round(auc_gb, 2)))
```

## Comparative of models accuracy

```{r}
models <- data.frame(Model = c('Random Forest',
                                      'Decision Tree',
                                      'Gradient'),
                            Accuracy = c(cm_rf$overall[1],
                                         cm_tree$overall[1],
                                         cm_gb$overall[1]))

#Plot comparing accuracy 
ggplot(aes(x=Model, y=Accuracy), data=models) +
  geom_bar(stat='identity', fill = 'blue') +
  ggtitle('Accuracy of the models') +
  xlab('Models') +
  ylab('Accuracy')

```





